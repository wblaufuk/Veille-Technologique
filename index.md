# Intelligence Artificielle, les mythes et la réalité


## _Si jamais vous lisez ce message, je n'ai pas encore terminé ma Veille Technologique. Je la terminerai dès que possible. Veuillez m'excuser du retard, merci de votre compréhension._



## William Blaufuks - 2019/2020

### MOS 4.4 : Nouvelles Technologies de l'Information et de la communication




## Introduction


L'objectif de cette veille technologique est de déconstruire les idées reçues sur l'intelligence artificielle, en explicant toutes les notions auxquelles elle est rattachée. Nous pourrons la redéfinir dans le contexte actuel, et comprendre ce qui en est réellement de l'avancé des recherches en IA en 2020. Nous arriverons ainsi à mieux comprendre les différents enjeux sociétaux liés à l'IA, qui impacteront grandement l'évolution de ce domaines dans les années à venir.


## Etat de l'art de l'Intelligence Artificielle


### Naissance de l'IA


L’intelligence artificielle est une discipline scientifique qui a vu officiellement le jour en 1956, au Dartmouth College, à Hanovre, aux États-Unis, lors d’une école d’été organisée par quatre chercheurs américains : John McCarthy, Marvin Minsky, Nathaniel Rochester et Claude Shannon. 


Pour John McCarthy et Marvin Minsky, comme pour les autres promoteurs de l’école d’été du Dartmouth College, l’intelligence artificielle visait initialement à la simulation, par des machines, des différentes facultés de l’intelligence. Leur objectif, pour ce domaine, était donc de modéliser les neurones par des méthodes mathématiques et statistiques [1].


Plus précisément, cette discipline scientifique reposait sur la conjecture selon laquelle toutes les fonctions cognitives, en particulier l’apprentissage, le raisonnement, le calcul, la perception, la mémorisation, voire même la découverte scientifique ou la créativité artistique, peuvent être décrites, avec une précision telle qu’il serait possible de programmer un ordinateur pour les reproduire [3].


### Historique


Au cours de son existence, l’intelligence artificielle a connu de nombreuses évolutions. On peut les résumer en six étapes [3].


1. _Le temps des prophètes_ : Tout d’abord, dans l’euphorie des origines et des premiers succès, les chercheurs s’étaient laissé aller à des déclarations un peu inconsidérées. C’est ainsi qu’en 1958, l’Américain Herbert Simon, qui deviendrait par la suite prix Nobel d’économie, avait déclaré que d’ici à dix ans les machines seraient championnes du monde aux échecs, si elles n’étaient pas exclues des compétitions internationales.


2. _Les années sombres_. Au milieu des années 1960, les progrès tardaient à se faire sentir. En 1965, Un enfant de dix ans avait battu un ordinateur au jeu d’échecs. Un rapport commandé par le Sénat américain faisait état, en 1966, des limitations intrinsèques de la traduction automatique. L’IA eut alors mauvaise presse pendant une dizaine d’années. Les investissements dans le domaine ont chuté et on est rentré dans l'hiver de l'IA.


3. _L'IA sémantique_. Les travaux ne s’interrompirent pas pour autant, mais on axa les recherches dans de nouvelles directions. On s’intéressa à la psychologie de la mémoire, aux mécanismes de compréhension, que l’on chercha à simuler sur un ordinateur, et au rôle de la connaissance dans le raisonnement. C’est ce qui donna naissance aux techniques de représentation sémantique des connaissances, qui se développèrent considérablement dans le milieu des années 1970, et conduisit aussi à développer des systèmes dits experts, parce qu’ils recouraient au savoir d’hommes de métiers, pour reproduire leurs raisonnements. Ces derniers suscitèrent d’énormes espoirs au début des années 1980 avec de multiples applications, par exemple pour le diagnostique médical.


4. _Néo Connexionnisme et apprentissage machine_. Le perfectionnement des techniques conduisit à l’élaboration d’algorithmes d’apprentissage machine (machine learning), qui permirent aux ordinateurs d’accumuler des connaissances et de se reprogrammer automatiquement à partir de leurs propres expériences. Cela donna naissance à des applications industrielles (identification d’empreintes digitales, reconnaissance de la parole, etc.), où des techniques issues de l’intelligence artificielle, de l’informatique, de la vie artificielle et d’autres disciplines se côtoyaient pour donner des systèmes hybrides.


5. _De l'IA aux interfaces hommes machines_. À partir de la fin des années 1990, on coupla l’intelligence artificielle à la robotique et aux interfaces homme-machine, de façon à produire des agents intelligents qui suggèrent la présence d’affects et d’émotions. Cela donna naissance, entre autres, au calcul des émotions (affective computing), qui évalue les réactions d’un sujet ressentant des émotions et les reproduit sur une machine, et surtout au perfectionnement des agents conversationnels (chatbots, Siri, etc).


6. _Rennaissance de l'IA_. Depuis 2010, la puissance des machines permet d’exploiter des données de masse (big data) avec des techniques d’apprentissage profond (deep learning), qui se fondent sur le recours à des réseaux de neurones formels. Des applications très fructueuses dans de nombreux domaines très en vogue (reconnaissance de la parole, des images, compréhension du langage naturel, voiture autonome, etc.) conduisent à parler d’une renaissance de l’intelligence artificielle.

<p align="center">
  <img src="https://pbs.twimg.com/media/DQQegB5X0AAIezL.jpg" width="700">
</p>
_Historique de l'IA, de sa création à aujourd'hui, Techjury_


### Applications actuelles


Les utilisations le l'IA se regroupent en plusieurs catégories, comme présentées dans le schéma suivant :



<p align="center">
  <img src="https://img1.lemondeinformatique.fr/fichiers/telechargement/ia.png" width="600">
</p>
_Les différentes techiques en IA, Le Monde Informatique_

Elles permettent notamment de produire, à l'heure actuelle, des outils extrêmement performants en reconnaissance d'image, reconnaissance vocale, chatbot, classification, prédiction de comportement, analyse des emotions, analyses stratégiques, etc. Ces techniques sont appliquées dans de nombreux secteurs différents : Industrie, Robotique, Logistique, Transports, Santé, Armées, Banques, Assurances, Jeux Vidéos, Service Client...


A l'heure actuelle, les technologies de l'IA les plus étudiées dans les travaux de recherches sont le _Natural Language Processing (NLP)_ et le _Machine Learning (ML)_, en particulier le _Deep Learning_. Ces dernières ont attirés des très grands investissements et s'avèrent très prometteuses. Leur récente emmergence s'explique par deux points :
- L'explosion du nombre de données récupérées et stockées par les grandes entreprises sur internet (Cf image ci-dessous).

- La croissance exponentielle de la puissance des processus de traitement, qui continue de croitre en suivant la loi de Moore.

<p align="center">
  <img src="http://infographic.statista.com/normal/chartoftheday_17727_global_data_creation_forecasts_n.jpg" width="600">
</p>
_Evolution des données dans le monde, Statista Digital Economy Compass 2019_


Le marché de l'Intelligence Artificielle en 2024 représentera 11,1 milliards de dollars. Selon un rapport de Venture Scanner, plus de 1550 jeunes pousses seraient consacrées à l’IA dans 70 pays. Avec une levée de fonds moyenne de 22 millions de dollars par entreprise, on atteint le montant record de 10 milliards de dollars levés au total par les start-up de l’intelligence artificielle [12].


## L'Intelligence Artificielle dans notre société.


### Perception de l'IA


Le terme "intelligence artificielle", qui à l’origine avait sans doute été donné pour frapper les esprits, est devenu très populaire au point qu’aujourd’hui, plus personne n'ignore que cette composante de l’informatique a pris de plus en plus d’ampleur au fil du temps, et que les technologies qui en sont issues ont grandement contribué à changer le monde pendant les soixante dernières années.


Cependant, le succès du terme "intelligence artificielle" repose parfois sur un malentendu lorsqu’il désigne une entité artificielle douée d’intelligence et qui, de ce fait, rivaliserait avec les êtres humains. C'est ce que l'on appelle plus communément _l'Intelligence Artificielle Générale_ (General Artificial Intelligence). 


Cette intelligence artificielle ne tient pour le moment que de la fiction, et aucun programme d'IA n'a  été capable jusqu'à présent de se rapprocher d'une telle technologie. Rien n’a pour l'instant permis ni de démentir, ni de démontrer irréfutablement cette conjecture qui demeure à la fois ouverte et féconde. 


Son existence a été introduite à travers beaucoup d'ouvrages différents. Dans le cinéma, on la retrouve dans plusieurs films. _Age of Ultron – Marvel_ (2015), _I, Robot_ (2004), _Terminator_ (1984), ou encore _2001, Odyssée de l'Espace_ (1968), font partis des nombreux films qui entretiennent la peur d'une intelligence artificielle qui pourrait atteindre le niveau d'intelligence des humains, et à termes se retourner contre eux et les conduire à leur propre perte [1].


La thèse de la singularité, selon laquelle une Intelligence Artificielle Générale sera capable de dépasser l’intelligence humaine au cours des toutes prochaines décennies, a récemment été réactivée par des personnalités du monde contemporain comme le physicien britannique Stephen Hawking, l’entrepreneur américain Elon Musk, ou encore le futuriste américain Ray Kurzweil [9]. Cette idée continue ainsi d’être considérée par certains comme une hypothèse crédible, malgré de multiples remises en cause de la part de spécialistes :


- Jean Ponce, chercheur en vision artificielle à l’ENS, en avril 2017 : « La Singularité, ça m’énerve. Je ne vois personnellement aucun indice que la machine intelligente soit plus proche de nous aujourd’hui qu’avant ».


- Jean-Louis Dessalles, chercheur en intelligence artificielle et en sciences cognitives, auteur de l’ouvrage « Des intelligences très artificielles », en février 2019 : « La question de la Singularité technologique ressemble à celle de la surpopulation sur Mars : on ne peut exclure que le problème se pose un jour, mais ce n’est pas demain ».


- Luc Julia, vice-président de l’innovation chez Samsung, inventeur de l’assistant vocal d’Apple, en mars 2019 : « Notre vision menaçante de l’intelligence des machines découle en partie de notre anthropomorphisme. Ces assistants ne sont que des mathématiques et des statistiques, ils répondent à des règles édictées en amont. Jamais une IA ne sera aussi intelligente qu’un humain » [4].


### Ce qui a porté à la confusion


Pour certains, cette thèse est avant tout défendue par des ingénieurs travaillant, en large partie, pour des géants technologiques et ayant l’impression, réelle ou exagérée, de changer le monde. on parle d’un « sentiment de vertige » et de puissance chez ces ingénieurs qui en viennent à surestimer la capacité des géants du numérique à bouleverser les réalités existantes et l’humanité [4].


La poularité de cette thèse se justifie aussi par l’envie de « se faire peur face à la technologie » : cette complaisance, juge-t-il, est véhiculée par certains médias qui préfèrent le spectaculaire à la réalité plus banale. Il prend ainsi l’exemple de l’idée selon laquelle il deviendra un jour possible de télécharger son propre esprit sur une machine afin de rendre son esprit immortel. Cette idée, portée notamment par un milliardaire russe ayant initié le projet 2045.com (qui, à son lancement, invitait l’internaute à appuyer sur un “bouton d’immortalité”), ne repose sur aucun fondement scientifique, et a pourtant été amplement médiatisée, contribuant ainsi à véhiculer les peurs et inquiétudes liées à l’IA [4][6].


Enfin, ces craintes remontent bien avant l’invention d’Internet et avant même l’arrivée des ordinateurs. Nous pourrons ainsi prendre l’exemple de Docteur Franckenstein, qui s'est finalement fait tué par le monstre qu'il avait crée ; ou encore celui d'une scène du film Fantasia, où plusieurs balais commencent à s’animer et à porter des seaux d’eau à la place du personnage principal. “Cette inquiétude-là, d’être dépassé un jour, me semble ancrée dans le cœur de l’homme. C’est pour cela que l’idée de Singularité est assez populaire” juge-t-il [4].


### Un outil marketing

- IA comme buzzword : Pour toujours attirer plus des lecteurs, de nombreux medias se nourrissent de la peur autour de l'IA en alimentant les discours alarmistes. On parle d'_IA Bashing_. L'intelligence artificielle fait fantasmer, et est trop souvent traitée sous des angles sociétaux ou philosophiques, manichéens et tenant plutôt de la science-fiction. Le sentiment que l’accumulation de prophéties catastrophistes a parfois empêché de faire entendre un discours plus nuancé, plus distancié. Le sensationnalisme l’a trop souvent emporté au détriment d’une réalité scientifique plus prosaïque, forcément moins spectaculaire. [8]

- l'IA comme outil de communication pour les entreprises : Le titre "intelligence artificielle" fait vendre, et les entreprises sont les premières à s'en être rendues compte. Cette technologie est synomyme, pour une grande partie de la société, de technologie futuriste, et de l'entrée dans une nouvelle de notre civilisation. Les sentiments de peur, d'admiration et d'incompréhension mélangés donnent aux entreprises et aux start-ups de la tech qui semble la maîtriser une image avant-gardiste, qu'ils essaient à tout prix d'entretenir pour garder la confiance de leurs clients. Certains profitent ainsi de la méconnaissance entourant ces sujets pour présenter leurs solutions sous un nouveau jour. C’est ainsi que des modèles statistiques utilisés avec un peu d’informatique connaissent parfois un toilettage marketing pour se transformer en outil d’« IA », ce qui sonne plus moderne. Une étude récente indiquait même que 40% des « startups IA » en Europe n’utiliseraient en réalité pas d’IA [4]. Ces pratiques pourraient avoir des conséquences économiques très néfastes, que l'on verra dans la suite. 


### Quelques critiques de cette intelligence

- _Intelligence Artificielle n'est capable d'être intelligente que dans des domaines extrêmement précis_. Luc Julia [1] explique habilement cela dans sa "courbe de la vie". Si l'on est actuellement capable de produire des IA plus performantes que l'homme dans certaines tâches très précises et dans des conditions données (par exemple au jeu d'échecs, jeu de Go, en classification d'images), ces programmes là sont incapable de performer, ne serait-ce que de manière médiocre, sur le reste de l'éventaille infinie de ce que sait faire l'intelligence humaine. Ce problème est structurellement lié aux programmes eux-mêmes : Matthieu Jonckheere explique que, pour un algorithme de machine learning, si la phase d’entraînement est trop approfondie, le modèle sera difficilement généralisable ; si elle est trop courte, il ne remplira pas sa fonction ».[5] 

- _Intelligence par unité d'énergie consommée_. La victoire du programme AlphaGo contre Lee Sedol, meilleur joueur du monde au Go, fut une nouvelle retentissente dans le milieu de l'intelligence artificielle. En effet, le jeu de Go est considéré comme l'un des plus complexes à traduire informatiquement, de par le nombre indescriptible de coups possibles à jouer et de strategies que l'on peut appliquer. Lors du match qui a eu lieu entre le 9 et 15 mars 2016 à Seoul, nous avons assisté à une nouvelle étape franchie par l'IA. Cependant, il est important de prendre du recul sur la valeur de cette victoire. La machine AlphaGo, qui fonctionnait en utilisant environ 1500 CPU, 300 GPU et quelques TPU, ce qui represente une energie total de 440 kW.h. En face d'elle, Lee Sedol n'utilisait que l'énergie de son cerveau, soit 20 W.h, et son cerveau devait par ailleurs se servir de cette energie pour se tenir droit, respirer, et faire fonctionner tout son corps [1]. La disproportion d'energie utilisé dans cet exercice montre donc les limitations encore réelles de l'IA, qui est encore très loin de se rapprocher des capacités du cerveaux humain.


## Impacts et risques

### Economiques

Comme nous l'avons vu, la notion "intelligence artificielle" est connotée par plusieurs idées différentes. 

Elle est d'une part vendue comme une technologie qui va révolutionner la vie sur terre, et qui sera à l'origine de l'emmergence de la "vie artificielle" et des robots dans nos sociétés. Cette innovation pourrait augmenter la qualité de nos vies et notre confort au quotidien, mais pose aussi le risque que les hommes ne soient plus capable de contenir cette technologie, qui deviendra plus puissante que l'homme et validera enfin la théorie de la singularité technologique. Ces idées sont maintenues par des entrepreneurs de la tech, des hommes politiques, des scientifiques, par les medias, ainsi que par un grand nombre de romanciers et réalisateurs de science-fiction.

A l'autre bout du spectre, beaucoup d'entreprises se servent de cet engouement autour de l'IA pour mieux se vendre. Certaines mentent et disent utiliser des programmes d'IA, pour mieux se vendre à leur clients et s'afficher comme à la pointe de la technologie. Dans beaucoup de cas, ces entreprises utilisent de simples programmes de calculs informatiques et de statistiques pour produire leurs résultats. Certaines jeunes start-ups ont même simulé l’intelligence artificielle en recourant à des humains en coulisses. 

<p align="center">
  <img src="https://miro.medium.com/max/700/1*x7P7gqjo8k2_bj2rTQWAfg.jpeg" width="450">
</p>
_How Companies sell AI, Medium_


Ce décalage, dans les deux sens, risque de rendre très difficile la prise au sérieux des entrepreneurs parlant d'intelligence artificielle. En conséquence, pour un grand nombre de fonds de capital-risque, une jeune pousse s’affirmant de l’intelligence artificielle ne sera plus prise au sérieux, ni perçue comme un investissement solide. A termes, les investissements risquent d'être  freinés et la recherche ralentie, si les attentes trop élevées des investisseurs ne retrouve pas les résultats, plus réalistes et parfois décevants, renvoyés par nos entreprises ; nous pourrions alors rentrer dans un deuxième hiver de l'IA. Pourtant, l’IA représente réellement une possible quatrième révolution industrielle tant les potentialités d’applications sont vastes [8].

L’intelligence artificielle, quand son expression n’est ni galvaudée, ni fantasmée, représente un tournant majeur dans l’évolution technologique effrénée que nous connaissons en ce début de XXIe siècle. Rater cette révolution desservirait assurément notre souveraineté numérique, et nous éloignerait de potentialités économiques dont nous ne mesurons pas encore la portée.


### Ethique et politiques

[10]
[4]




## Sources

[1] "l'Intelligence Artificielle n'existe pas" (conférence), Luc Julia, ITES Innovation Summit (7e édition), 22/05/2019, [Source 1](https://www.youtube.com/watch?v=rXbjGZ_BupY&feature=youtu.be)

[2] "10 Machine Learning Methods that Every Data Scientist Should Know", Jorge Castañón, medium, 01/05/2019, [Source 2](https://towardsdatascience.com/10-machine-learning-methods-that-every-data-scientist-should-know-3cc96e0eeee9)

[3] "Intelligence artificielle, entre mythe et réalité", JAESA, iatranshumanisme, 28/10/2018, [Source 3](https://iatranshumanisme.com/2018/10/26/intelligence-artificielle-entre-mythe-et-realite/)

[4] "Mythes et légendes de l'intelligence artificielle", Clément Jeanneau, signaux faibles, 11/05/2019, [Source 4](https://signauxfaibles.co/2019/05/11/mythes-et-legendes-de-lintelligence-artificielle/)

[5] "IA : « Souvent, ce qu’on appelle Big Data, ça n’existe pas »", Gaétan Raoul, LeMagIT, 03/02/2020, [Source 5](https://www.lemagit.fr/actualites/252477780/IA-Souvent-ce-quon-appelle-Big-Data-ca-nexiste-pas)

[6] "Elon Musk is wrong. The AI singularity won't kill us all", Toby Walsh, Wired, 20/09/2017, [Source 6](https://www.wired.co.uk/article/elon-musk-artificial-intelligence-scaremongering)

[7] "Algorithmes : entre mythes et réalités", JAESA, iatranshumanisme, 04/11/2019, [Source 7](https://iatranshumanisme.com/2019/11/04/algorithmes-entre-mythes-et-realites/)

[8] "Pour en finir avec l’«IA washing» et l’«IA bashing»", Jean-Philippe Poisson, Les Echos, 21/01/2020, [Source 8](https://www.lesechos.fr/idees-debats/cercle/opinion-pour-en-finir-avec-lia-washing-et-lia-bashing-1164690)

[9] "How Far Are We From Achieving Artificial General Intelligence ?", Naveen Joshi, Forbes, 10/06/2019, [Source 9](https://www.forbes.com/sites/cognitiveworld/2019/06/10/how-far-are-we-from-achieving-artificial-general-intelligence/#684fc456dc4d)

[10] "IA et éthique ? CALMONS NOUS", Jérome Fortias, LinkedIn, 20/01/2020, [Source 10](http://linkedin.com/pulse/ia-et-%25C3%25A9thique-calmons-nous-jerome-fortias/?trackingId=sldxrtKkQsaHvUSalfvviw%3D%3D)

[11] "Pourquoi l'intelligence artificielle a besoin  d'éthique", Laura Wojcik, Le Monde, 03/04/2019, [Source 11](https://www.youtube.com/watch?v=tf4-_4IbXPs)

[12] "Les 5 chiffres à absolument connaître sur l'IA", Microsoft, 10/07/2017, [Source 12](https://experiences.microsoft.fr/business/intelligence-artificielle-ia-business/ia-chiffres-cles/)
